# 08장. 순환 신경망

# 1. 기억을 갖는 신경망 모델 RNN

- 순차 데이터(Sequence Data) : 시간적 공간적 순서 관계가 있는 데이터
- 시공간의 순서 관계로 형성되는 문맥, 콘텍스트를 가짐

## 1. 연상 기억을 하는 홉필드 네트워크

- 연상 메모리 : 기억 저장, 연상
- 새로운 입력이 들어오면 특정 패턴으로 수렴하게 만들어 기억해둔 패턴 연상
- 순환 연산을 통해 입력 데이터의 패턴 연상

## 2. 기억을 전달하는 순환 신경망(RNN, Recurrent Neural Network)

- 데이터의 순차 구조 인식, 데이터의 콘텍스트 범위가 넓더라도 처리 가능

### 1. 순차 구조를 인식하며 콘텍스트를 기억하는 모델 구조

- 데이터를 시간 순서대로 하나씩 입력받음
- 은닉 계층에 피드백 연결을 가짐
- 은닉 상태 : 시간 단계별로 입력된 데이터가 순차적으로 추상화되어 형성된 콘텍스트
- 피드백 연결 : 시간의 흐름에 따라 콘텍스트를 기억하는 과정

### 2. 순환 연결 방식

- 입력 계층은 새로운 입력 데이터를 입력받음
- 이전 상태와 입력 데이터를 합침
- 함수를 실행해서 은닉 상태 출력
- 함수는 순환 신경망의 종류에 따라 달라짐, 은닉 계층의 가중치 적용
- 은닉 상태는 출력 계층과 다음 단계의 은닉 계층에 전달
- 출력 계층은 은닉 상태를 입력받아 뉴련 연산 후 출력

### 3. 기본 순환 신경망 모델

$$
h_t=\tanh(W_{hh}h_{t-1}+W_{xh}x_t)
\\=\tanh((W_{hh}W_{xh})\begin{pmatrix} h_{t-1} \\ x_t \end{pmatrix})
\\=\tanh(W\begin{pmatrix} h_{t-1} \\ x_t \end{pmatrix}), \ W=(W_{hh}W_{xh})
$$

## 3. 순환 신경망의 입력, 은닉 상태, 출력

$$
h_1=f_w(h_0, \ x_1)
\\ h_2=f_w(h_1, \ x_2)
\\ \cdots
\\ h_t=f_w(h_{t-1}, \ x_t)
$$

$$
h_t=f_w(f_w(\cdots f_w(f_w(f_w(h_0, \ x_1), x_2), x_3), \cdots, x_{t-1}), x_t)
$$

$$
h_t=f_w(h_{t-1}, \ x_t)
$$

- 순차 구조 포착 가능
- 가변 길이 데이터 처리 쉬움
- 파라미터 수 절약, 정규화 효과

# 2. 순환 신경망의 주요 모델

## 1. 다대일 모델(Many-to-One)

- 입력은 순차열, 출력은 순차열이 아님
- 모든 단계에서 입력, 마지막 단계에서만 출력

## 2. 다대다 모델(Many-to-Many)

- 입출력의 길이가 같은 순차열일 때 사용
- 모든 단계에서 입력, 모든 단계에서 출력
- 티처 포싱(Teacher Forcing) : 현재 단계의 출력을 다음 단계에 입력하는 방법

## 3. 일대다 모델(One-to-Many)

- 입력은 순차열이 아님, 출력은 순차열
- 첫 번째 단계에서만 입력, 모든 단계에서 출력

## 4. 양방향 모델(Bidirectional)

- 입력을 양쪽으로 살펴봄
- 공간적 순서 관계 → 상대적인 순서

## 5. 인코더-디코더 모델(Encoder-Decoder)

- 입력과 출력의 길이가 서로 다른 순차열
- 인코더 : 입력 데이터 요약
- 디코더 : 요약 데이터 → 출력 데이터 생성
- Seq2Seq(Sequence-to-Sequence) 모델
