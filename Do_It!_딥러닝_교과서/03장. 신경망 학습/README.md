# 03장. 신경망 학습

# 1. 신경망 학습의 의미

- 경험 데이터로부터 데이터에 내재한 정보와 규칙을 찾아서 추론 능력을 만드는 과정

### 1. 입출력의 매핑 규칙은 어떤 형태로 존재할까?

- 함수적 매핑 관계
- 가중 합산과 활성 함수가 연결되어 뉴런 구성 → 뉴런이 모여 계층 구성 → 계층이 쌓여 신경망의 계층 구조 정의

### 2. 입출력의 매핑 규칙에서 학습해야 할 것들

- 신경망 모델의 가중치와 편향 조정 → 최적의 값
- 최적화(Optimization) 기법 : 함수의 해를 근사적으로 찾는 방법

# 2. 신경망 학습과 최적화

## 1. 최적화란?

- 유한한 방정식으로 정확한 해를 구할 수 없을 때 근사적으로 해를 구하는 방법
- 다양한 제약 조건을 만족하면서 목적 함수를 최대화하거나 최소화하는 해를 반복하여 조금씩 접근하는 방식으로 찾아가는 방법

### 1. 최적화 문제의 표준 형태

$$
\min_{x \in D} \ \ \ \ f(x)
\\ \text{subject to} \ \ \ \ g_i(x) \leq 0, \ i=1, ..., m
\\ h_j(x)=0, \ j=1, ..., r
$$

- 목적 함수(Objective Function) $f(x)$ + 제약 조건 $g_i(x) \leq 0, h_j=0$
- 표준 최적화 문제 : 변수 $x$에 대한 등식과 부등식으로 표현되는 여러 제약 조건을 만족하면서 목적 함수인 $f(x)$를 최소화하는 $x$의 값을 찾는 문제
- 수렴한다(Converge) : 최적해(Optimal Solution)에 점점 가까이 가는 상태

### 2. 최소화 문제와 최대화 문제의 관계

- 목적 함수의 부호 변환으로 최대화, 최소화 변환 가능
- 최소화 문제의 목적 함수 : 비용 함수(Cost Function), 손실 함수(Loss Function)
- 최대화 문제의 목적 함수 : 유틸리티 함수(Utility Function)

## 2. 신경망 학습을 위한 최적화 문제 정의

### 1. 회귀 문제를 최적화 문제로 정의한다면?

- 타깃과 예측값의 오차를 최소화하는 파라미터를 찾으라
    
    $$
    \min_{\theta} \ \ \frac{1}{N}\sum_{i=1}^N\left\| t_i-y(x_i; \ \theta)\right\|^2_2
    $$
    
- 손실 함수 : 평균제곱오차(MSE, Mean Square Error)

### 2. 분류 문제를 최적화 문제로 정의한다면?

- 관측 확률분포와 예측 확률분포의 차이를 최소화하는 파라미터를 찾으라
    
    $$
    \min_{\theta} \ \ -\frac{1}{N}\sum_{i=1}^N\sum_{k=1}^Kt_{ik}  \ \cdot \ \log\mu(x_i; \ \theta)_k
    $$
    
- 손실 함수 : 크로스 엔트로피(Cross Entropy)

## 3. 최적화를 통한 신경망 학습

- 최적화 : 손실 함수의 최소 지점을 찾아가는 과정
