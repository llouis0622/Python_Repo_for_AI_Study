# 06장. 콘벌루션 신경망

# 1. 시각 패턴 인식을 위한 신경망 모델

## 1. 생체 시각 시스템을 모방한 인공 신경망

- 네오코그니트론(Neocognitron)

### 1. 생체 신경망의 계층적 시각 정보 처리

- 동물 시각 피질의 구조와 기능
- 뉴런은 아주 좁은 영역의 자극에 반응 : 수용 영역(Receptive Field)
- 뉴런마다 다른 모양의 특징을 인식하도록 뉴런의 역할이 나뉨
- 뉴런은 계층 구조를 이루며 시각 정보를 계층적으로 처리

## 2. 콘벌루션 신경망(CNN, Convolution Neural Network)의 탄생

- 네오코그니트론의 설계 사상과 모델 구조를 따름
- 학습 알고리즘 : 역전파 알고리즘
- 르넷-5(LeNet-5) : 콘벌루션 계층 + 서브샘플링 계층

# 2. 콘벌루션 신경망의 구조

## 1. 콘벌루션 연산

- 두 함수를 곱해서 적분하는 연산

### 1. 콘벌루션 연산

- $g(t)$ : 콘벌루션 필터(Convolution Filter), 콘벌루션 커널(Convolution Kernel)

$$
(f*g)(t)\triangleq\int^\infty_{-\infty}f(\tau)g(t-\tau)d\tau
$$

### 2. 교차상관(Cross Correlation) 연산

- 두 함수의 유사도를 측정하는 연산

$$
(f*g)(t)\triangleq\int^\infty_{-\infty}f(\tau)g(t+\tau)d\tau
$$

## 2. 이미지 콘벌루션 연산

- 이미지 특징 추출, 변환
- 경계선 검출(Edge Detection), 스무딩(Smoothing), 샤프닝(Sharpening)

### 1. 경계선 검출 이미지 콘벌루션 연산 정의

$$
(I*K)(i, \ j)=\sum_m\sum_nI(m, \ n)K(i-m, \ j-n)
$$

$$
(I*K)(i, \ j)=\sum_m\sum_nI(m, \ n)K(i+m, \ j+n)
$$

### 2. 이미지 콘벌루션 연산 과정

$$
y_{11}=w_{11}x_{11}+w_{12}x_{12}+w_{13}x_{13}
\\+w_{21}x_{21}+w_{22}x_{22}+w_{23}x_{23}
\\+w_{31}x_{31}+w_{32}x_{32}+w_{33}x_{33}
$$

$$
y_{12}=w_{11}x_{12}+w_{12}x_{13}+w_{13}x_{14}
\\+w_{21}x_{22}+w_{22}x_{23}+w_{23}x_{24}
\\+w_{31}x_{32}+w_{32}x_{33}+w_{33}x_{34}
$$

### 3. 콘벌루션 필터의 슬라이딩 순서

- 2차원 공간에서 슬라이딩 → 가로 방향과 세로 방향의 순서 정함
- 가로 방향 한 줄 슬라이딩 → 세로 방향으로 한 칸씩 아래로 이동

### 4. 이미지 콘벌루션 필터 설계 예시

- 경계선 검출 : 이미지에서 사물의 경계를 찾는 연산, 인접한 픽셀의 변화량 계산
- 스무딩 : 이미지의 색깔이 부드럽게 변하도록 만드는 연산, 주별 픽셀 가중 합산
- 샤프닝 : 이미지를 선명하게 만드는 연산, 라플라스 필터 사용

## 3. 콘벌루선 신경망의 콘벌루션 연산

- 데이터에 내포된 다양한 특징을 추출하도록 특징에 따라 별도의 콘벌루션 필터를 둠
- 콘벌루션 필터의 크기와 개수는 계층별로 특징의 추상화 수준에 따라 다르게 설계
- 콘벌루션 필터의 값은 데이터의 특징을 잘 추출하도록 학습을 통해 정함

### 1. 입력 데이터의 형태

- 3차원 텐서(Tensor) : [Width] × [Height] × [Depth]
- 공간 특징(Spatial Feature) : [Width] × [Height]
- 채널 특징(Channel Feature) : [Depth]

### 2. 콘벌루션 필터의 형태

- 3차원 텐서 : [Width] × [Height] × [Depth]
- 콘벌루션 필터의 [Depth] = 입력 데이터의 [Depth]

### 3. 콘벌루션 필터의 크기와 개수

- 신경망 성능이 최대화되도록 정해야 함
- 3×3, 5×5, 7×7

### 4. 표준 콘벌루션 연산

- 모든 채널에 대해 한꺼번에 가중 합산

### 5. 콘벌루션 신경망의 뉴런은 어디에 있을까?

$$
w^Tx+b
$$

### 6. 지역 연결을 갖고 가중치를 공유하는 뉴런

- 이미지 영역과 콘벌루션 필터가 가중 합산될 때 뉴런의 가중 합산 연산 실행
- 지역 연결(Local Connectivity) : 입력 데이터의 모든 차원과 연결되는 대신 콘벌루션 필터와 겹쳐진 영역에만 연결

### 7. 액티베이션 맵(Activation Map)의 생성

- 액티베이션 맵 : 콘벌루션 연산 결과로 만들어지는 이미지, 피처 맵
- 픽셀 : 각 뉴런의 출력

### 8. 콘벌루션 필터 개수와 같은 액티베이션 맵의 채널 수

- 새로운 콘벌루션 필터로 콘벌루션을 할 때마다 액티베이션 맵 추가

### 9. 두 번째 계층의 콘벌루션 연산

- 콘벌루션 필터의 채널 수 = 입력 데이터의 채널 수

### 10. 뉴런의 활성 함수 실행

- 3차원 텐서에 활성 함수 실행 : 모든 뉴런에 활성 함수 일괄 실행

### 11. 순방향 신경망의 계층과 비교

- 뉴런은 콘벌루션 필터 크기의 지역 연결을 가짐
- 같은 채널의 뉴런들은 콘벌루션 필터의 가중치 공유

## 4. 콘벌루션 신경망에서 서브샘플링 연산

- 서브샘플링(Subsampling) : 데이터를 낮은 빈도로 샘플링했을 때의 샘플을 근사하는 연산, 다운샘플링(Downsamping)
- 풀링(Pooling) : 이미지 크기를 줄이는 연산

### 1. 풀링 연산을 이용한 서브샘플링

- 이미지상에서 풀링 필터를 슬라이딩하면서 요약 통계량을 구하는 연산
- 평균, 최댓값, 최소, 가중 합산, $L_2$ 노름
- 맥스 풀링(Max Pooling) : 최댓값을 사용하는 풀링 연산, 입력 데이터의 가장 두드러진 특징 추출
- 평균 풀링(Average Pooling) : 평균을 사용하는 풀링 연산, 입력 데이터의 평균적인 특징 추출

### 2. 콘벌루션을 이용한 서브샘플링 연산

- 슬라이딩 간격 조정

### 3. 콘벌루션 신경망에서 풀링 연산

- 계층별로 풀링 필터의 크기와 슬라이딩 간격 지정
- Conv + ReLU + Pooling

### 4. 풀링 필터의 크기와 위치불변성

- 콘벌루션 연산을 여러 번 하고 풀링 연산 수행
- 어떤 크기의 수용 영역 내에서 위치불변성을 줄 것인가를 결정하는 문제

### 5. 콘벌루션 신경망 구성 예시

- 계층이 깊어질수록 액티베이션 맵 크기 감소, 채널 수 증가
    
    ![1.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/81ce352b-f505-4b7c-ba55-561d76267295/53dd8071-7d47-472e-8d39-0d3adc48caac/1.png)
    

## 5. 스트라이드(Stride)

- 콘벌루션 연산과 풀링 연산을 할 때 필터의 슬라이딩 간격
- 서브샘플링 없이 특징 학습 : 한 칸씩 슬라이딩
- 서브샘플링 : 두 칸씩 슬라이딩
- $N \times N$ 이미지, $F \times F$ 콘벌루션 필터
    
    $$
    O=\frac{N-F}{S}+1
    $$
    

## 6. 패딩(Padding)

- 데이터를 일정 크기로 만들기 위해 더미 데이터를 추가하는 방법
- $N$ 이미지 크기, $P$ 패딩
    
    $$
    O=\frac{(N+2\times P)-F}{S}+1
    $$
    
    $$
    P=\frac{(O-1)\times S-(N-F)}{2}
    $$
    

## 7. 신경망 깊이와 수용 영역의 관계

- 계층 $L$의 출력 크기를 알 때 입력 데이터의 크기 계산
    
    $$
    N=(O_L-1)\times S^L+(F-1)\times S^{L-1}+\cdots+(F-1)\times S^1+F
    $$
    
- 뉴런의 수용 영역 계산
    
    $$
    L번째 \ 계층의 \ 뉴런 \ 수용 \ 영역=(F-1)\times S^{L-1}+\cdots+(F-1)\times S^1+F
    $$

# 3. 콘벌루션 신경망의 가정 사항

## 1. 콘벌루션 연산의 성질

- 매우 강한 사전 분포(Infinitely Strong Prior) : 일부 파라미터를 사용하지 않음
- 희소 연결(Sparse Connectivity) : 입력 데이터와 겹치는 영역에만 연결되고 나머지 영역에서는 연결이 없음
    
    $$
    O(k\times n)
    $$
    
- 파라미터 공유(Parameter Sharing) : 동일한 콘벌루션 필터로 콘벌루션을 함
    
    $$
    O(k)
    $$
    
- 이동등변성(Translation Equivariance) : 위치에 상관없이 동일한 지역 특징 인식 가능
    
    $$
    f(g(x))=g(f(x))
    $$
    

## 2. 풀링 연산의 성질

- 위치불변성(Positional Invariance) : 입력이 아주 작게 이동했을 때 출력이 바뀌지 않는 성질
    
    $$
    f(x)=f(g(x))
    $$
    

# 4. 개선된 콘벌루션 연산

- 표준 콘벌루션 연산 한계
    - 파라미터 수와 계산량 많음
    - 죽은 채널이 발생해도 알기 어려움
    - 여러 채널에 대해 한꺼번에 연산 → 공간 특징과 채널 특징 구분 어려움

## 1. 팽창 콘벌루션(Dilated Convolution)

### 1. 뉴런의 수용 영역을 넓힐 때 문제점

- 콘벌루션 필터 크기 증가, 신경망 깊이 증가 → 파라미터 수, 계산량 증가
- 서브샘플링 계층 추가 → 이미지 공간 특징 손실

### 2. 공간 특징을 유지하며 수용 영역을 넓히는 팽창 콘벌루션

- 팽창 콘벌루션 필터 : 콘벌루션 필터의 수용 픽셀 간격을 띄위서 필터를 넓게 만듦
- 팽창 : 수용 픽셀 간격

## 2. 점별 콘벌루션(Pointwise Convolution)

- 가로×세로 크기가 1×1인 콘벌루션 필터 사용
- 채널 특징 학습, 죽은 채널 영향 감소

## 3. 그룹 콘벌루션(Group Convolution)

- 채널을 여러 그룹으로 나눠서 콘벌루션하는 방식
- 파라미터 계산 절약, 채널 간 상관관계 구조 학습 가능

## 4. 깊이별 콘벌루션(Depthwise Convolution)

- 각 채널의 공간 특징 학습 → 채널별 콘벌루션 연산 수행 이후 결과 재결합
- 입력 채널 수 = 출력 채널 수

## 5. 깊이별 분리 콘벌루션(Depthwise Seperable Convolution)

- 깊이별 콘벌루션 + 점별 콘벌루션
- 공간 특징, 채널 특징 별도 학습, 계산량 8~9배 감소

## 6. 셔플 그룹 콘벌루션(Shuffled Grouped Convolution)

- 주기적으로 그룹 간에 채널을 섞어서 정보가 교환되도록 만든 그룹 콘벌루션 방식

## 7. 공간 분리 콘벌루션(Spatially Seperable Convolution)

- 정사각형 콘벌루션 필터를 가로 방향 필터와 세로 방향 필터로 인수분해
- 최적해가 아닌 준최적해를 찾을 수도 있음

# 5. 업샘플링(Upsampling) 연산

- 이미지 크기를 키우는 연산
- 세그멘테이션(Segmentation) : 이미지 영역을 분할하는 방법

## 1. 언풀링(Unpooling)

- 풀링의 반대 연산, 요약된 통계 데이터를 요약하기 전 크기의 데이터로 복구하는 연산
- 바늘방석 언풀링(Bed of Nails) : 첫 번째 픽셀은 원래 값으로 채우고 나머지 픽셀은 0으로 채우는 방법
- 최근접 이웃 언풀링(Nearest Neighbor) : 모두 원래의 픽셀값으로 채우는 방법
- 맥스 언풀링(Max Unpooling) : 다운샘플링과 업샘플링이 대칭을 이루는 모델 구조에서만 사용, 맥스 풀링을 할 때 최댓값의 위치를 기억해 두었다가 언풀링을 할 때 기억해 둔 위치로 값을 복원하고 나머지는 0으로 채움

## 2. 트랜스포즈 콘벌루션(Transposed Convolution)

- 콘벌루션 필터를 학습하듯이 업샘플링 필터도 학습하도록 만든 방식
- 콘벌루션 행렬의 전치 행렬로 연산 표현 가능
    
    $$
    W=\begin{bmatrix} 
      x & y & z & 0 & 0 & 0 \\
      0 & x & y & z & 0 & 0 \\
      0 & 0 & x & y & z & 0 \\
      0 & 0 & 0 & x & y & z \\
      \end{bmatrix}
    $$
    
    $$
    w*x=Wx
    \\ \begin{bmatrix} 
      x & y & z & 0 & 0 & 0 \\
      0 & x & y & z & 0 & 0 \\
      0 & 0 & x & y & z & 0 \\
      0 & 0 & 0 & x & y & z \\
      \end{bmatrix}
    \begin{bmatrix} 
      0 \\
      a \\
      b \\
      c \\
      d \\
      0
      \end{bmatrix}=
    \begin{bmatrix} 
      ax+bz \\
      ax+by+cz \\
      bx+cy+dz \\
      cx+dy \\
      \end{bmatrix}
    $$
    
    $$
    w*^Tx=W^Tx
    \\ \begin{bmatrix} 
      x & 0 & 0 & 0 \\
      y & x & 0 & 0 \\
      z & y & x & 0 \\
      0 & z & y & x \\
      0 & 0 & z & y \\
      0 & 0 & 0 & z
      \end{bmatrix}
    \begin{bmatrix} 
      a \\
      b \\
      c \\
      d
    \end{bmatrix}=
    \begin{bmatrix} 
      ax \\
      ay+bx \\
      az+by+cx \\
      bz+cy+dx \\
      cz+dy \\
      dz
      \end{bmatrix}
    $$
    
    $$
    W=\begin{bmatrix} 
      x & y & z & 0 & 0 \\
      0 & 0 & x & y & z \\
      \end{bmatrix}
    $$
    
    $$
    \begin{bmatrix} 
      x & y & z & 0 & 0 \\
      0 & 0 & x & y & z \\
      \end{bmatrix}
    \begin{bmatrix} 
      0 \\ a \\ b \\ c \\ d
      \end{bmatrix}
    =\begin{bmatrix} 
      ay+bz \\
      bx+cy+dz \\
      \end{bmatrix}
    $$
    
    $$
    \begin{bmatrix} 
      x & 0 \\ y & 0 \\ z & x \\ 0 & y \\ 0 & z
      \end{bmatrix}
    \begin{bmatrix} 
      a \\ b
      \end{bmatrix}=
    \begin{bmatrix} 
      ax \\ ay \\ az+bx \\ by \\ bz
      \end{bmatrix}
    $$
