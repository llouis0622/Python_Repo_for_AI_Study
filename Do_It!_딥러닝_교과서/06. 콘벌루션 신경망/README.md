# 06장. 콘벌루션 신경망

# 1. 시각 패턴 인식을 위한 신경망 모델

## 1. 생체 시각 시스템을 모방한 인공 신경망

- 네오코그니트론(Neocognitron)

### 1. 생체 신경망의 계층적 시각 정보 처리

- 동물 시각 피질의 구조와 기능
- 뉴런은 아주 좁은 영역의 자극에 반응 : 수용 영역(Receptive Field)
- 뉴런마다 다른 모양의 특징을 인식하도록 뉴런의 역할이 나뉨
- 뉴런은 계층 구조를 이루며 시각 정보를 계층적으로 처리

## 2. 콘벌루션 신경망(CNN, Convolution Neural Network)의 탄생

- 네오코그니트론의 설계 사상과 모델 구조를 따름
- 학습 알고리즘 : 역전파 알고리즘
- 르넷-5(LeNet-5) : 콘벌루션 계층 + 서브샘플링 계층

# 2. 콘벌루션 신경망의 구조

## 1. 콘벌루션 연산

- 두 함수를 곱해서 적분하는 연산

### 1. 콘벌루션 연산

- $g(t)$ : 콘벌루션 필터(Convolution Filter), 콘벌루션 커널(Convolution Kernel)

$$
(f*g)(t)\triangleq\int^\infty_{-\infty}f(\tau)g(t-\tau)d\tau
$$

### 2. 교차상관(Cross Correlation) 연산

- 두 함수의 유사도를 측정하는 연산

$$
(f*g)(t)\triangleq\int^\infty_{-\infty}f(\tau)g(t+\tau)d\tau
$$

## 2. 이미지 콘벌루션 연산

- 이미지 특징 추출, 변환
- 경계선 검출(Edge Detection), 스무딩(Smoothing), 샤프닝(Sharpening)

### 1. 경계선 검출 이미지 콘벌루션 연산 정의

$$
(I*K)(i, \ j)=\sum_m\sum_nI(m, \ n)K(i-m, \ j-n)
$$

$$
(I*K)(i, \ j)=\sum_m\sum_nI(m, \ n)K(i+m, \ j+n)
$$

### 2. 이미지 콘벌루션 연산 과정

$$
y_{11}=w_{11}x_{11}+w_{12}x_{12}+w_{13}x_{13}
\\+w_{21}x_{21}+w_{22}x_{22}+w_{23}x_{23}
\\+w_{31}x_{31}+w_{32}x_{32}+w_{33}x_{33}
$$

$$
y_{12}=w_{11}x_{12}+w_{12}x_{13}+w_{13}x_{14}
\\+w_{21}x_{22}+w_{22}x_{23}+w_{23}x_{24}
\\+w_{31}x_{32}+w_{32}x_{33}+w_{33}x_{34}
$$

### 3. 콘벌루션 필터의 슬라이딩 순서

- 2차원 공간에서 슬라이딩 → 가로 방향과 세로 방향의 순서 정함
- 가로 방향 한 줄 슬라이딩 → 세로 방향으로 한 칸씩 아래로 이동

### 4. 이미지 콘벌루션 필터 설계 예시

- 경계선 검출 : 이미지에서 사물의 경계를 찾는 연산, 인접한 픽셀의 변화량 계산
- 스무딩 : 이미지의 색깔이 부드럽게 변하도록 만드는 연산, 주별 픽셀 가중 합산
- 샤프닝 : 이미지를 선명하게 만드는 연산, 라플라스 필터 사용

## 3. 콘벌루선 신경망의 콘벌루션 연산

- 데이터에 내포된 다양한 특징을 추출하도록 특징에 따라 별도의 콘벌루션 필터를 둠
- 콘벌루션 필터의 크기와 개수는 계층별로 특징의 추상화 수준에 따라 다르게 설계
- 콘벌루션 필터의 값은 데이터의 특징을 잘 추출하도록 학습을 통해 정함

### 1. 입력 데이터의 형태

- 3차원 텐서(Tensor) : [Width] × [Height] × [Depth]
- 공간 특징(Spatial Feature) : [Width] × [Height]
- 채널 특징(Channel Feature) : [Depth]

### 2. 콘벌루션 필터의 형태

- 3차원 텐서 : [Width] × [Height] × [Depth]
- 콘벌루션 필터의 [Depth] = 입력 데이터의 [Depth]

### 3. 콘벌루션 필터의 크기와 개수

- 신경망 성능이 최대화되도록 정해야 함
- 3×3, 5×5, 7×7

### 4. 표준 콘벌루션 연산

- 모든 채널에 대해 한꺼번에 가중 합산

### 5. 콘벌루션 신경망의 뉴런은 어디에 있을까?

$$
w^Tx+b
$$

### 6. 지역 연결을 갖고 가중치를 공유하는 뉴런

- 이미지 영역과 콘벌루션 필터가 가중 합산될 때 뉴런의 가중 합산 연산 실행
- 지역 연결(Local Connectivity) : 입력 데이터의 모든 차원과 연결되는 대신 콘벌루션 필터와 겹쳐진 영역에만 연결

### 7. 액티베이션 맵(Activation Map)의 생성

- 액티베이션 맵 : 콘벌루션 연산 결과로 만들어지는 이미지, 피처 맵
- 픽셀 : 각 뉴런의 출력

### 8. 콘벌루션 필터 개수와 같은 액티베이션 맵의 채널 수

- 새로운 콘벌루션 필터로 콘벌루션을 할 때마다 액티베이션 맵 추가

### 9. 두 번째 계층의 콘벌루션 연산

- 콘벌루션 필터의 채널 수 = 입력 데이터의 채널 수

### 10. 뉴런의 활성 함수 실행

- 3차원 텐서에 활성 함수 실행 : 모든 뉴런에 활성 함수 일괄 실행

### 11. 순방향 신경망의 계층과 비교

- 뉴런은 콘벌루션 필터 크기의 지역 연결을 가짐
- 같은 채널의 뉴런들은 콘벌루션 필터의 가중치 공유

## 4. 콘벌루션 신경망에서 서브샘플링 연산

- 서브샘플링(Subsampling) : 데이터를 낮은 빈도로 샘플링했을 때의 샘플을 근사하는 연산, 다운샘플링(Downsamping)
- 풀링(Pooling) : 이미지 크기를 줄이는 연산

### 1. 풀링 연산을 이용한 서브샘플링

- 이미지상에서 풀링 필터를 슬라이딩하면서 요약 통계량을 구하는 연산
- 평균, 최댓값, 최소, 가중 합산, $L_2$ 노름
- 맥스 풀링(Max Pooling) : 최댓값을 사용하는 풀링 연산, 입력 데이터의 가장 두드러진 특징 추출
- 평균 풀링(Average Pooling) : 평균을 사용하는 풀링 연산, 입력 데이터의 평균적인 특징 추출

### 2. 콘벌루션을 이용한 서브샘플링 연산

- 슬라이딩 간격 조정

### 3. 콘벌루션 신경망에서 풀링 연산

- 계층별로 풀링 필터의 크기와 슬라이딩 간격 지정
- Conv + ReLU + Pooling

### 4. 풀링 필터의 크기와 위치불변성

- 콘벌루션 연산을 여러 번 하고 풀링 연산 수행
- 어떤 크기의 수용 영역 내에서 위치불변성을 줄 것인가를 결정하는 문제

### 5. 콘벌루션 신경망 구성 예시

- 계층이 깊어질수록 액티베이션 맵 크기 감소, 채널 수 증가
    
    ![1.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/81ce352b-f505-4b7c-ba55-561d76267295/53dd8071-7d47-472e-8d39-0d3adc48caac/1.png)
    

## 5. 스트라이드(Stride)

- 콘벌루션 연산과 풀링 연산을 할 때 필터의 슬라이딩 간격
- 서브샘플링 없이 특징 학습 : 한 칸씩 슬라이딩
- 서브샘플링 : 두 칸씩 슬라이딩
- $N \times N$ 이미지, $F \times F$ 콘벌루션 필터
    
    $$
    O=\frac{N-F}{S}+1
    $$
    

## 6. 패딩(Padding)

- 데이터를 일정 크기로 만들기 위해 더미 데이터를 추가하는 방법
- $N$ 이미지 크기, $P$ 패딩
    
    $$
    O=\frac{(N+2\times P)-F}{S}+1
    $$
    
    $$
    P=\frac{(O-1)\times S-(N-F)}{2}
    $$
    

## 7. 신경망 깊이와 수용 영역의 관계

- 계층 $L$의 출력 크기를 알 때 입력 데이터의 크기 계산
    
    $$
    N=(O_L-1)\times S^L+(F-1)\times S^{L-1}+\cdots+(F-1)\times S^1+F
    $$
    
- 뉴런의 수용 영역 계산
    
    $$
    L번째 \ 계층의 \ 뉴런 \ 수용 \ 영역=(F-1)\times S^{L-1}+\cdots+(F-1)\times S^1+F
    $$
