# 05장. 초기화와 정규화

- 모델 초기화(Model Initialization) : 손실 함수에서 출발 위치를 결정하는 방법

# 1. 가중치 초기화

## 1. 상수 초기화

### 1. 가중치를 0으로 초기화한다면?

$$
z=w^Tx+b=0
$$

$$
a=\text{activation}(x)\in\{0, \ 0.5\}
$$

$$
\frac{\partial z}{\partial x}=w=0
$$

$$
\frac{\partial J}{\partial x}=\frac{\partial J}{\partial z}\cdot\frac{\partial z}{\partial x}=0
$$

### 2. 가중치를 0이 아닌 상수로 초기화한다면?

- 가중 합산 결과도 같고 활성 함수의 실행 결과도 같음
- 대칭성 → 하나의 뉴런만 있는 것과 동일

## 2. 가우시안 분포 초기화

- 대칭성 피하기 → 가중치를 모두 다른 값으로 초기화
- 난수 활용 → 균등 분포, 가우시안 분포

### 1. 가중치를 아주 작은 난수로 초기화한다면?

- 계층이 깊어질수록 출력이 점점 0으로 변함

### 2. 가중치를 큰 난수로 초기화한다면?

- 입력 데이터가 각 계층을 지나면서 점점 1이나 -1로 변함

### 3. 적정한 가중치는 어떤 값일까?

- 데이터가 계층을 통과하더라도 데이터의 크기를 유지해주는 가중치로 초기화해야 함

## 3. Xavier 초기화(Xavier Initialization)

- 시그모이드 계열의 활성 함수를 사용할 때 가중치를 초기화하는 방법
- 입력 데이터의 분산이 출력 데이터에서 유지되도록 가중치를 초기화함

### 1. Xavier 초기화 방식의 가정사항

- 활성 함수를 선형 함수로 가정
- 입력 데이터와 가중치는 서로 독립임

### 2. Xavier 초기화 식의 유도 과정

$$
y=z=w_1x_1+w_2x_2+\cdots+w_nx_n+b
$$

$$
\text{Var}(y)=\text{Var}(w_1x_1+w_2x_2+\cdots+w_nx_n)
\\ =\text{Var}(w_1x_1)+\text{Var}(w_2x_2)+\cdots+\text{Var}(w_nx_n)
\\ =\sum^n_{i=1}\text{Var}(w_ix_i)
$$

$$
\text{Var}(y)=\sum^n_{i=1}\text{Var}(x_i)\text{Var}(w_i)
$$

$$
\text{Var}(y)=n\text{Var}(x_i)\text{Var}(w_i)
$$

$$
\text{Var}(w_i)=\frac{1}{n}
$$

## 4. He 초기화(He Initialization)

- 활성 함수가 ReLU일 때 Xavier 초기화의 한계점을 개선한 방식
- 가중치의 분산을 $\frac{2}{n}$으로 만듦
    
    $$
    \text{Var}(w_i)=\frac{2}{n}
    $$
    

# 2. 정규화(Regularization)

- 최적화 과정에서 최적해를 잘 찾도록 정보를 추가하는 기법

## 1. 일반화 오류

- 일반화(Generalization) : 훈련 데이터가 아닌 새로운 데이터에 대해 모델이 예측을 얼마나 잘하는지를 가리킴
- 일반화 오류(Generalization Error) : 모델의 훈련 성능과 검증/테스트 성능의 차

## 2. 정규화 접근 방식

- 모델을 최대한 단순하게 만듦
- 사전 지식을 표현해서 최적해를 빠르게 찾도록 함
- 확률적 성질을 추가
- 여러 가설을 고려하여 예측

# 3. 배치 정규화

## 1. 내부 공변량 변화(Internal Covariate Shift)

- 데이터 분포가 보이지 않는 요인에 의해 왜곡되는 현상
- 내부 공변량 : 분포를 결정하는 보이지 않는 요인

## 2. 배치 정규화(Batch Normalization) 단계

- 데이터가 계층을 지날 때마다 매번 정규화해서 내부 공변량 변화를 없애는 방법
- 모델의 계층 형태로 데이터 정규화 실행
- 미니 배치에 대해 정규화함

### 1. 표준 가우시안 분포로 정규화

$$
\hat{x}^{(k)}=\frac{x^{(k)}-\mathbb{E}[x^{(k)}]}{\sqrt{\text{Var}[x^{(k)}]}}, \ k=1, 2, \cdots, d
$$

- 데이터가 계층을 지날 때마다 표준 가우시안 분포로 바뀜 → 내부 공변량의 변화 최소화

### 2. 원래 분포로 복구

- 모델이 표현하려던 비선형성을 제대로 표현할 수 없음
- 데이터를 표준 가우시안 분포로 정규화 → 다시 원래 데이터의 분포로 복구
    
    $$
    y^{(k)} \sim \mathcal{N}(\beta^{(k)}, \ \gamma^{(k)})
    $$
    
    $$
    y^{(k)}=\gamma^{(k)}\hat{x}^{(k)}+\beta^{(k)}
    $$
    

## 3. 배치 정규화 알고리즘

- 입력 : 미니배치 $\mathcal{B}=\{x_{1 \cdots m} \}$, 학습 파라미터 $\gamma$, $\beta$
- 출력 : $\{y_i=\text{BN}_{\gamma, \beta}(x_i)\}$
    
    $$
    \mu_B\leftarrow\frac{1}{m}\sum^m_{i=1}x_i
    $$
    
    $$
    \sigma^2_B\leftarrow\frac{1}{m}\sum^m_{i=1}(x_i-\mu_B)^2
    $$
    
    $$
    \hat{x}_i\leftarrow\frac{1}{\sqrt{\sigma^2_B+\epsilon}}\odot(x_i-\mu_B)
    $$
    
    $$
    y_i\leftarrow\gamma\odot\hat{x}_i+\beta=\text{BN}_{\gamma, \beta}(x_i)
    $$
    

### 1. 배치 정규화 수행 위치

- 뉴런의 가중 합산과 활성 함수 사이에서 수행하는 것으로 제안
- 활성 함수를 실행한 뒤에 배치 정규화를 수행했을 때 더 나은 성능을 보임

## 4. 이미지 정규화 기법

- 계층 정규화(Layer Normalization) : 이미지 샘플별로 정규화, 미니배치 크기와 무관, RNN
- 인스턴스 정규화(Instance Normalization) : 샘플의 채널별로 정규화, 스타일 변환, GAN
- 그룹 정규화(Group Normalization) : 샘플의 채널 그룹을 나눠서 정규화, 미니배치 크기가 작음

## 5. 배치 정규화의 우수성

- 내부 공변량 변화 최소화 → 그레이디언트의 흐름 원활, 안정적 학습 진행
- 지속적인 데이터 분포 유지 → 초기화 방법 의존도 감소, 높은 학습률
- 미니배치 단위 정규화 → 확률적 성질 보유, 모델 성능 증가

# 4. 가중치 감소(Weight Decay)

- 학습 과정에서 작은 크기의 가중치를 찾게 만드는 정규화 기법

## 1. 가중치 감소 적용 방식

- 가중치의 크기를 제한하는 제약 조건으로서 손실 함수의 일부 항으로 표현
    
    $$
    \tilde{J}(w)=J(w)+\lambda R(w)
    $$
    
- 리지 회귀(Ridge Regression)
    
    $$
    \tilde{J}(w)=J(w)+\frac{\lambda}{2}\|w\|^2_2
    $$
    
- 라소 회귀(Lasso Regression)
    
    $$
    \tilde{J}(w)=J(w)+\lambda\|w\|_1
    $$
    
    $$
    \tilde{J}(w)=J(w)+\sum^L_{i=1}\frac{\lambda_i}{2}\|w_i\|^2_2
    $$
    

## 2. 가중치의 사전 분포와 노름

- 가우시안 분포 : $L_2$ 노름
- 라플라스 분포 : $L_1$ 노름
    
    $$
    f(x|\mu, \ b)=\frac{1}{2b}e^{-\frac{|x-\mu|}{b}}
    $$
    

### 1. 가중치 감소 정규화 항의 노름 유도 과정

- 다변량 가우시안 분포(Multivariate Gaussian Distribution)
    
    $$
    \mathcal{N}(x|\mu, \ \Sigma)=\frac{1}{\sqrt{2\pi^D}|\Sigma|^{1/2}}e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}
    $$
    
    $$
    -\log\mathcal{N}(w|0, \ \text{I})=\frac{1}{2}\|w\|^2_2+\text{const}
    $$
    
    $$
    -\log f(w|0, \ \text{I})=\|w\|_1+\text{const}
    $$
    

## 3. 정규화 효과

- $L_2$ 정규화 : 최적해 원점 주변 존재
- $L_1$ 정규화 : 최적해 특정 차원의 축 위에 있을 가능성 높음

# 5. 조기 종료(Early Stopping)

- 모델이 과적합되기 전에 훈련을 멈추는 정규화 기법
    
    ![1.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/81ce352b-f505-4b7c-ba55-561d76267295/0c46f314-7ebf-48a4-a79f-ff264f5e7a4a/1.jpg)
    

## 1. 조기 종료 기준

- 모델의 성능이 향상하지 않더라도 바로 종료해서는 안됨
- 어떤 성능을 기준으로 조기 종료를 할 것인지 정함

## 2. 조기 종료의 정규화 효과

- 파라미터 공간을 작게 만듦
- 조기 종료 = $L_2$ 정규화
    
    ![1.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/81ce352b-f505-4b7c-ba55-561d76267295/31125225-d007-4c72-a25b-4f05b226195c/1.png)
    

# 6. 데이터 증강(Data Augmentation)

- 훈련 데이터셋을 이용해서 새로운 데이터를 생성

## 1. 데이터 증강 기법

- 훈련 데이터를 조금씩 변형해서 새로운 데이터를 만드는 방법
- 훈련 데이터의 분포를 학습해서 생성 모델을 만든 뒤에 새로운 데이터를 생성

### 1. 데이터 증강은 어떤 방식으로 실행해야 할까?

- 훈련 과정에서 실시간으로 데이터 증강
- 훈련 데이터를 읽어서 모델에 입력하기 전에 데이터 증강 → 확률적인 방식으로 매번 다른 형태가 되도록 변형 → 무한히 많은 데이터가 있는 것과 같은 효과

## 2. 클래스 불변 가정(Class-Invariance Assumption)

- 데이터를 증강할 때 클래스가 바뀌지 않도록 해야 함

## 3. 데이터 증강 방식 선택

- 자동 데이터 증강(Automatic Data Augmentation) : 데이터 증강 방식을 자동으로 찾아줌

# 7. 배깅(Bagging : Bootstrap Aggregating)

- 앙상블(Ensemble) : 여러 모델을 실행해서 하나의 강한 모델을 만드는 기법
- 배깅 : 독립된 여러 모델을 동시에 실행한 뒤 개별 모델의 예측을 이용해서 최종으로 예측

## 1. 배깅의 원리

- 모델의 종류와 관계없이 다양한 모델로 팀 구성 가능
- 부트스트랩(Bootstrap) : 표본 데이터로 모집단의 통계량을 추정할 때 통계량을 여러 번 측정해서 오차 및 신뢰 구간 추정
- 모델의 독립성을 보장하기 위해 훈련 데이터를 부트스트랩함

### 1. 여러 모델의 추론 결과를 이용하는 배깅의 추론 방식

- 다수결 투표 방식(Majority Voting) : 가장 많이 나온 값으로 예측

### 2. 신경망 모델로 배깅할 때 다른 점

- 모델의 가중치 랜덤 초기화 → 다른 모델인 것 같은 효과
- 미니배치 방식 → 모델별로 다른 훈련 데이터셋 사용하는 효과

## 2. 배깅의 정규화 효과

$$
\epsilon_i\sim\mathcal{N}(0, \Sigma)(i=1, 2, \cdots, k)
$$

$$
\mathbb{E}[\epsilon^2_i]=v, \mathbb{E}[\epsilon_i\epsilon_j]=c
$$

$$
\epsilon_b=\frac{1}{k}\sum^k_{i=1}\epsilon_i
$$

### 1. 배깅의 오차 크기

$$
\text{Var}(\epsilon_b)=\mathbb{E}[(\frac{1}{k}\sum^k_+{i=1}\epsilon_i)^2]
$$

$$
\text{Var}(\epsilon_b)=\frac{1}{k}v+\frac{k-1}{k}c
$$

### 2. 모델이 서로 독립이 아니라면?

$$
\text{Var}(\epsilon_b)=\frac{1}{k}v+\frac{k-1}{k}v=v
$$

### 3. 모델이 서로 독립이라면?

$$
\text{Var}(\epsilon_b)=\frac{1}{k}v+\frac{k-1}{k}0=\frac{v}{k}
$$

# 8. 드롭아웃(Dropout)

- 미니배치를 실행할 때마다 뉴런을 랜덤하게 잘라내서 새로운 모델을 생성하는 정규화 방법
- 무한히 많은 모델의 평균으로 예측 → 적은 자원으로 배깅 정규화 효과

## 1. 학습 단계

- 뉴런 드롭아웃 : 50% 이상 유지
- 뉴런 유지할 확률 : 입력 뉴런 0.8, 은닉 뉴런 0.5

### 1. 드롭아웃을 하면 어떤 모델이 생성될까?

- 뉴런 50% 유지, 나머지 50% 드롭아웃

### 2. 이진 마스크를 활용한 뉴런의 드롭아웃

- 이진 마스크 : 뉴런별 드롭아웃 여부 나타냄
    
    $$
    a^{(l)}=\text{activation}(W^{(l)T}x^{(l)}+b^{(l)})
    \\ r^{(l)}\sim Bern(p)
    \\ \tilde{a}^{(l)}=a^{(l)}\odot r^{(l)}
    $$
    

## 2. 추론 단계

- 뉴런을 드롭아웃하지 않고 훈련 과정에서 확률적으로 생성했던 다양한 모델 평균 예측

### 1. 무한히 많은 모델의 평균 계산

$$
w_1x+w_2y
\\ w_1x+0y
\\ 0x+0y
\\ 0x+w_2y
$$

$$
\mathbb{E}[a]=\frac{1}{2}(w_1x+w_2y)
$$

- 가중치 비례 추론 규칙(Weight Scaling Inference Rule) : 모델의 가중치를 스케일링해서 모델 평균 계산
    
    $$
    a^{(l)}=\text{activation}(W^{(l)T}x^{(l)}+b^{(l)})\times p
    $$
    

### 2. 역드롭아웃(Inverted Dropout)

- 훈련 시점에 각 계층의 출력을 미리 $p$로 나눠 두면 원래의 추론 코드를 그대로 사용 가능
    
    $$
    a^{(l)}=\text{activation}(W^{(l)T}x^{(l)}+b^{(l)})
    \\ r^{(l)}\sim Bern(p)
    \\ \tilde{a}^{(l)}=(a^{(l)}\odot r^{(l)})/p
    $$
    

# 9. 잡음 주입

- 데이터나 모델이 확률적으로 정의되지 않음 → 잡음을 넣어 확률적 성질 부여
- 현재 상태를 평균으로 보고 잡음으로 변형된 데이터를 생성해서 특정한 분포를 따름

## 1. 잡음 주입 방식

### 1. 입력 데이터에 잡음 주입

- 데이터 증강 기법
- 아주 작은 분산을 갖는 잡음 → 가중치 감소

### 2. 특징에 잡음 주입

- 데이터가 추상화된 상태에서 데이터 증강
- 객체와 같은 상대적으로 의미 있는 단위로 데이터 증강

### 3. 모델 가중치에 잡음 주입

- 드롭아웃
- 가중치의 불확실성과 관련
- 가중치의 그레이디언트 크기를 작게 만듦

### 4. 최적해가 평지 위에 있으면 좋은 이유

- 훈련 데이터의 손실 함수의 최소가 평평한 곳에 위치 → 최소가 조금 이동한 위치에 있더라도 발생 손실 감소

## 2. 소프트 레이블링

### 1. 레이블이 정확하지 않다면?

- 모델이 정확히 1이나 0으로 예측 불가 → 일정량의 손실 발생, 최적화 불가능

### 2. 레이블에 잡음 주입

- 소프트 레이블링(Soft Labeling) : 타깃 클래스의 확률은 $\epsilon$만큼 작게 만들고 나머지 클래스들의 확률은 $\epsilon$을 배분해서 확률 부여
- 하드 레이블링(Hard Labeling) : 레이블을 0과 1로 만드는 것
